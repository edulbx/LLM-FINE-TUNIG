{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSHlAbqzDFDq"
      },
      "source": [
        "<!-- Eduardo Lima Barros -->\n",
        "# <font color='White'>Eduardo Lima Barros</font>\n",
        "## <font color='White'>Generative IA for LLM - Llama-2-7b-chat-hf</font>\n",
        "## <font color='White'>Fine-Tuning with QLoRA for sentiment analisys</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFy-uAhz1OOh"
      },
      "source": [
        "## Instalando e Carregando Pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9kKetyp1OOi"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U watermark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8EUCYFk7W5W"
      },
      "source": [
        "A descrição de cada um dos pacotes abaixo está disponível no Capítulo 7 do Curso.\n",
        "\n",
        "https://www.datascienceacademy.com.br/course/ia-generativa-e-llms-para-processamento-de-linguagem-natural"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yBspMX-1OOi"
      },
      "outputs": [],
      "source": [
        "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJOiFhsI1OOi"
      },
      "outputs": [],
      "source": [
        "!pip install -q trl==0.4.7 gradio==3.37.0 protobuf==3.20.3 scipy==1.11.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCscFWU11OOi"
      },
      "outputs": [],
      "source": [
        "!pip install -q sentencepiece==0.1.99 tokenizers==0.13.3 datasets==2.16.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRozZWGN1OOi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d6dba3f-76bd-41f4-d9d2-c6d4cf24bcce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Data Science Academy\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%reload_ext watermark\n",
        "%watermark -a \"Data Science Academy\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAMzy_0FtaUZ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import torch\n",
        "import datasets\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from transformers import (AutoModelForCausalLM,\n",
        "                          AutoTokenizer,\n",
        "                          BitsAndBytesConfig,\n",
        "                          HfArgumentParser,\n",
        "                          TrainingArguments,\n",
        "                          pipeline,\n",
        "                          logging)\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCjC_MHpAKQP"
      },
      "outputs": [],
      "source": [
        "# Define o nível de log para CRITICAL\n",
        "logging.set_verbosity(logging.CRITICAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmFTqTOG61YC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "954b2f30-811a-4e96-9d0c-be207d5fa026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de GPUs: 1\n",
            "Modelo GPU: NVIDIA A100-SXM4-40GB\n",
            "Total Memória [GB] da GPU: 42.481811456\n"
          ]
        }
      ],
      "source": [
        "# Verifica o modelo da GPU\n",
        "if torch.cuda.is_available():\n",
        "    print('Número de GPUs:', torch.cuda.device_count())\n",
        "    print('Modelo GPU:', torch.cuda.get_device_name(0))\n",
        "    print('Total Memória [GB] da GPU:',torch.cuda.get_device_properties(0).total_memory / 1e9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kw4uSDl76z-N"
      },
      "outputs": [],
      "source": [
        "# Reset da memória da GPU\n",
        "from numba import cuda\n",
        "device = cuda.get_current_device()\n",
        "device.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZArexSp1OOj"
      },
      "outputs": [],
      "source": [
        "# Define o nome do dataset\n",
        "nome_dataset = \"dataset.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFjD_NF8n8kt"
      },
      "outputs": [],
      "source": [
        "# Carrega os dados\n",
        "dataset_carregado = load_dataset('csv', data_files = nome_dataset, delimiter = ',')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dados Carregados no Formato de Dicionário\n",
        "dataset_carregado"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcMKEnkT9UZr",
        "outputId": "74e06c74-f1c9-4e85-bc1d-83266c93ce1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['train'],\n",
              "        num_rows: 17057\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/NousResearch/Llama-2-7b-chat-hf"
      ],
      "metadata": {
        "id": "60qumlGz8YI3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe_vsFJs1XPG"
      },
      "outputs": [],
      "source": [
        "# Nome do repositório do LLM pré-treinado\n",
        "repositorio_hf = \"NousResearch/Llama-2-7b-chat-hf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbPqgPsv1OOj"
      },
      "outputs": [],
      "source": [
        "# Nome do novo modelo\n",
        "modelo_dsa = \"novo_modelo_dsa\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definindo os Parâmetros de Configuração"
      ],
      "metadata": {
        "id": "J7B7VikzQp3X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bauIDIDh1OOj"
      },
      "outputs": [],
      "source": [
        "# Parâmetros LoRA\n",
        "lora_r = 32\n",
        "lora_alpha = 16\n",
        "lora_dropout = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os parâmetros acima são do LoRa (Low-Rank Adaptation), a parte base do QLoRA (Quantized Low-Rank Adaptation), uma técnica utilizada para adaptar modelos de linguagem de forma eficiente. Acima dos parâmetros LoRa colocamos os parâmetros de quantização, definindo assim o QLoRa.\n",
        "\n",
        "Vamos descrever cada um dos parâmetros:\n",
        "\n",
        "**lora_r**: Este parâmetro representa o \"rank\" na adaptação de Low-Rank (LoRA). Um valor de 32 significa que a matriz de pesos do modelo original será aproximada por duas matrizes menores cujo produto possui um rank máximo de 32. Essencialmente, isso reduz a complexidade computacional e o número de parâmetros a serem treinados durante a adaptação, mantendo a eficácia do modelo.\n",
        "\n",
        "**lora_alpha**: Este é um fator de escala que é aplicado às atualizações de peso do LoRA durante o treinamento. Um valor de 16 indica que as atualizações de pesos serão escaladas por este fator. Esse parâmetro é importante porque permite um controle fino sobre a magnitude das atualizações dos pesos, o que pode afetar a rapidez e a eficácia da adaptação do modelo.\n",
        "\n",
        "**lora_dropout**: Este parâmetro representa a taxa de \"dropout\" aplicada durante a adaptação do modelo. O valor 0.1 significa que 10% das unidades serão aleatoriamente descartadas (ou \"desligadas\") durante o treinamento. O dropout é uma técnica comum para evitar o overfitting em redes neurais, garantindo que o modelo não se torne excessivamente dependente de qualquer parte específica dos dados de treinamento."
      ],
      "metadata": {
        "id": "uybfqsE7-0jZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4iDCe5R1OOj"
      },
      "outputs": [],
      "source": [
        "# Parâmetros bitsandbytes (QLoRa)\n",
        "use_4bit = True\n",
        "bnb_4bit_compute_dtype = \"float16\"\n",
        "bnb_4bit_quant_type = \"nf4\"\n",
        "use_nested_quant = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os parâmetros acima são para a biblioteca bitsandbytes, uma ferramenta para otimização de treinamento de modelos de aprendizado de máquina, em particular para reduzir o uso de memória e acelerar o treinamento. Aqui está a explicação de cada parâmetro:\n",
        "\n",
        "**use_4bit**: Este parâmetro indica se a quantização de 4 bits deve ser usada ou não. Ao definir True, isso significa que o modelo irá utilizar uma representação de 4 bits para os pesos durante o treinamento. Isso reduz significativamente a quantidade de memória necessária, permitindo treinar modelos maiores ou reduzir os requisitos de hardware.\n",
        "\n",
        "**bnb_4bit_compute_dtype**: Este é o tipo de dado usado para cálculos durante o treinamento quando a quantização de 4 bits está ativa. O valor float16 significa que os cálculos serão feitos usando números de ponto flutuante de 16 bits. Isso é geralmente usado para equilibrar a eficiência computacional e a precisão numérica.\n",
        "\n",
        "**bnb_4bit_quant_type**: Especifica o tipo de quantização a ser usado. O valor nf4 é um tipo específico de quantização desenvolvido pela bitsandbytes, otimizado para eficiência e eficácia em treinamento de modelos de aprendizado profundo. Este tipo de quantização é projetado para manter a precisão do modelo enquanto reduz os requisitos de memória.\n",
        "\n",
        "**use_nested_quant**: Indica se uma técnica de quantização aninhada será usada. False significa que essa técnica não será empregada. A quantização aninhada pode ser usada para reduzir ainda mais o uso de memória, aplicando diferentes níveis de quantização a diferentes partes do modelo, mas pode ser mais complexa de implementar e gerenciar.\n",
        "\n",
        "Esses parâmetros são usados para configurar como o modelo de aprendizado profundo irá lidar com a representação e cálculo dos pesos durante o treinamento, visando otimizar o uso de memória e acelerar o processo de treinamento."
      ],
      "metadata": {
        "id": "jCqGrqMz_oZ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhvC2CvF1OOj"
      },
      "outputs": [],
      "source": [
        "# Parâmetros do ajuste fino\n",
        "output_dir = \"saida\"\n",
        "num_train_epochs = 1\n",
        "fp16 = True\n",
        "bf16 = False\n",
        "per_device_train_batch_size = 4\n",
        "per_device_eval_batch_size = 4\n",
        "gradient_accumulation_steps = 1\n",
        "gradient_checkpointing = True\n",
        "max_grad_norm = 0.3\n",
        "learning_rate = 2e-4\n",
        "weight_decay = 0.001\n",
        "optim = \"paged_adamw_32bit\"\n",
        "lr_scheduler_type = \"cosine\"\n",
        "max_steps = -1\n",
        "warmup_ratio = 0.03"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os parâmetros acima são usados para configurar o processo de ajuste fino (fine-tuning) de modelos de aprendizado de máquina, especialmente modelos de linguagem natural. Vamos descrever cada um deles:\n",
        "\n",
        "**output_dir**: Especifica o diretório onde os resultados do treinamento serão salvos.\n",
        "\n",
        "**num_train_epochs**: O número de épocas de treinamento. O valor 1 significa que o modelo passará uma vez por todo o conjunto de dados de treinamento.\n",
        "\n",
        "**fp16**: Indica se deve ser usado o treinamento com precisão mista de ponto flutuante de 16 bits (FP16). O valor True significa que sim, o que pode acelerar o treinamento e reduzir o uso de memória, mantendo uma precisão aceitável.\n",
        "\n",
        "**bf16**: Semelhante ao fp16, mas para o formato bfloat16. False significa que não será utilizado. O formato bfloat16 é outra forma de reduzir o uso de memória e acelerar o treinamento, com impactos ligeiramente diferentes na precisão. Podemos usar fp16 ou bf16, mas não podemos usar ambos simultaneamente.\n",
        "\n",
        "**per_device_train_batch_size**: Tamanho do lote de treinamento por dispositivo. O valor 4 indica que cada dispositivo de treinamento (como uma GPU) processará 4 exemplos por lote.\n",
        "\n",
        "**per_device_eval_batch_size**: Tamanho do lote de avaliação por dispositivo, também definido como 4.\n",
        "\n",
        "**gradient_accumulation_steps**: Número de passos para acumulação de gradientes antes de realizar uma atualização de parâmetros. O valor 1 significa que não há acumulação (cada passo resulta em uma atualização).\n",
        "\n",
        "**gradient_checkpointing**: Habilita o checkpointing de gradientes, que é uma técnica para reduzir o uso de memória ao custo de um tempo de treinamento ligeiramente maior. True indica que está habilitado.\n",
        "\n",
        "**max_grad_norm**: Norma máxima para o corte de gradientes. O valor 0.3 é um valor que ajuda a evitar o problema de explosão de gradientes em treinamentos.\n",
        "\n",
        "**learning_rate**: Taxa de aprendizado inicial. O valor 2e-4 é um valor comum para ajuste fino, proporcionando um equilíbrio entre a velocidade de aprendizado e a estabilidade.\n",
        "\n",
        "**weight_decay**: Taxa de decaimento de peso, usada para regularização. O valor 0.001 é um valor que ajuda a prevenir o overfitting.\n",
        "\n",
        "**optim**: O otimizador usado. \"paged_adamw_32bit\" é uma variante do AdamW otimizado para eficiência em termos de memória.\n",
        "\n",
        "**lr_scheduler_type**: Tipo de agendador de taxa de aprendizado. O valor \"cosine\" indica o uso do agendador cosseno, que ajusta a taxa de aprendizado seguindo uma curva cosseno.\n",
        "\n",
        "**max_steps**: Número máximo de passos de treinamento. O valor -1 significa que o treinamento continuará até que o número de épocas seja alcançado.\n",
        "\n",
        "**warmup_ratio**: Proporção do número total de passos de treinamento usados para o aquecimento linear da taxa de aprendizado. O valor 0.03 significa que 3% do treinamento inicial será usado para aumentar gradualmente a taxa de aprendizado.\n",
        "\n",
        "Esses parâmetros são essenciais para configurar de maneira eficiente o processo de ajuste fino, impactando diretamente na qualidade do modelo treinado, no tempo de treinamento e no uso de recursos computacionais."
      ],
      "metadata": {
        "id": "1Y-OD5X9BLom"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-y-YqQIO1OOj"
      },
      "outputs": [],
      "source": [
        "# Agrupando sequências em lotes de mesmo comprimento\n",
        "group_by_length = True\n",
        "save_steps = 0\n",
        "logging_steps = 400"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Projeto Desenvolvido na Data Science Academy - www.datascienceacademy.com.br -->\n",
        "Os parâmetros acima são usados para configurar certos aspectos do processo de treinamento de modelos de aprendizado de máquina, especialmente modelos de linguagem. Eles estão relacionados a como as sequências são agrupadas em lotes e como o progresso do treinamento é registrado e salvo. Vamos detalhar cada um:\n",
        "\n",
        "**group_by_length**: Este parâmetro indica se as sequências devem ser agrupadas por comprimento ao formar lotes de treinamento. Quando True, isso significa que o treinamento agrupará sequências de comprimentos semelhantes juntas em um lote. Esta é uma prática eficiente porque reduz a quantidade de preenchimento (padding) necessário. O preenchimento é usado para garantir que todas as sequências em um lote tenham o mesmo comprimento, mas pode ser um desperdício de recursos computacionais. Agrupar sequências de comprimentos semelhantes minimiza esse desperdício.\n",
        "\n",
        "**save_steps**: Especifica a frequência com que o modelo treinado deve ser salvo. Um valor de 0 indica que o modelo não será salvo automaticamente com base em um número de passos. Em vez disso, o modelo pode ser salvo no final de cada época de treinamento ou manualmente.\n",
        "\n",
        "**logging_steps**: Define a frequência com que as informações de log devem ser registradas. O valor 400 significa que o processo de treinamento registrará informações como a perda de treinamento (loss), métricas de avaliação, entre outros, a cada 400 passos de treinamento. Isso é útil para monitorar o progresso do treinamento e para o ajuste fino dos hiperparâmetros."
      ],
      "metadata": {
        "id": "QZBqDmeXC2Ye"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5-jclzon8nz"
      },
      "outputs": [],
      "source": [
        "# Precisão dos dados para treinamento\n",
        "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código acima está relacionado à configuração do tipo de dado (dtype) para computação durante o treinamento de modelos de rede neural usando a biblioteca PyTorch. Vamos analisar cada parte do código:\n",
        "\n",
        "**torch**: É uma referência à biblioteca PyTorch, uma biblioteca para aprendizado de máquina e redes neurais.\n",
        "\n",
        "**bnb_4bit_compute_dtype**: Esta é uma variável que armazena uma string representando o tipo de dado desejado para computação. O parâmetro bnb_4bit_compute_dtype foi definido como \"float16\", indicando que a computação deve ser realizada usando números de ponto flutuante de 16 bits.\n",
        "\n",
        "**getattr**: É uma função Python built-in usada para obter um atributo de um objeto. Neste caso, ela está sendo usada para obter um atributo da biblioteca PyTorch com base no valor da string armazenada em bnb_4bit_compute_dtype.\n",
        "\n",
        "O que acontece aqui é que getattr(torch, bnb_4bit_compute_dtype) recupera o tipo de dados de ponto flutuante de 16 bits (torch.float16) da biblioteca PyTorch, com base no valor de bnb_4bit_compute_dtype. Em seguida, esse tipo de dados é atribuído à variável compute_dtype.\n",
        "\n",
        "O uso de compute_dtype no treinamento de modelos de rede neural tem implicações importantes:\n",
        "\n",
        "**Eficiência de Memória**: Usar float16 ao invés de tipos de dados mais comuns como float32 pode reduzir significativamente o uso de memória, permitindo o treinamento de modelos maiores ou a execução de mais processos em paralelo.\n",
        "\n",
        "**Velocidade de Computação**: Muitas GPUs modernas têm otimizações para cálculos float16, o que pode acelerar o treinamento.\n",
        "\n",
        "**Precisão**: Embora float16 possa ser menos preciso do que float32, muitas vezes é suficientemente preciso para tarefas de treinamento de modelos de rede neural."
      ],
      "metadata": {
        "id": "KORbxhs_DgFg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jetJVp9n8rN"
      },
      "outputs": [],
      "source": [
        "# Definindo os parâmetros da quantização\n",
        "bnb_config = BitsAndBytesConfig(load_in_4bit = use_4bit,\n",
        "                                bnb_4bit_quant_type = bnb_4bit_quant_type,\n",
        "                                bnb_4bit_compute_dtype = compute_dtype,\n",
        "                                bnb_4bit_use_double_quant = use_nested_quant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-n7bDY5n8w5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4a736b9f243946c4884f498413df2d65",
            "dcb025fcf9674fe9b4acfd4a8d2806c6",
            "409755f60a624dbda1dcf83df61ff640",
            "536d6ff66192425ca393c55cd6052a20",
            "3b5d13958f5d4cc4862fa940b1e50cde",
            "6ed73dfb1b0b4c068eea4d8af22589b7",
            "0ce4e980d36740d68d0e5bf404fbde12",
            "94791cbdf7a341cc9a94ac0f289aecb4",
            "dfa63bc79f99408292f36b090082a5de",
            "b5ef973d5a294f129ecad6545980f872",
            "ace4cf0d1c0e4bcfa18bf8aedec77b9f"
          ]
        },
        "outputId": "c5482a7f-d33b-435c-a687-1d012ea8c454"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a736b9f243946c4884f498413df2d65"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Carregando o modelo base pré-treinado\n",
        "modelo = AutoModelForCausalLM.from_pretrained(repositorio_hf,\n",
        "                                              quantization_config = bnb_config,\n",
        "                                              device_map = \"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1x315Frn8zg"
      },
      "outputs": [],
      "source": [
        "# Não usaremos o cache\n",
        "modelo.config.use_cache = False\n",
        "modelo.config.pretraining_tp = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiFQiy4HpxH_"
      },
      "outputs": [],
      "source": [
        "# Carregando o tokenizador do modelo base\n",
        "tokenizador = AutoTokenizer.from_pretrained(repositorio_hf, trust_remote_code = True)\n",
        "tokenizador.pad_token = tokenizador.eos_token\n",
        "tokenizador.padding_side = \"right\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCTzpQP1pxKz"
      },
      "outputs": [],
      "source": [
        "# Carregando a configuração LoRA\n",
        "peft_config = LoraConfig(lora_alpha = lora_alpha,\n",
        "                         lora_dropout = lora_dropout,\n",
        "                         r = lora_r,\n",
        "                         bias = \"none\",\n",
        "                         task_type = \"CAUSAL_LM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gIMSx1KpxN6"
      },
      "outputs": [],
      "source": [
        "# Definindo os parâmetros de treino\n",
        "training_arguments = TrainingArguments(output_dir = output_dir,\n",
        "                                       num_train_epochs = num_train_epochs,\n",
        "                                       per_device_train_batch_size = per_device_train_batch_size,\n",
        "                                       gradient_accumulation_steps = gradient_accumulation_steps,\n",
        "                                       optim = optim,\n",
        "                                       save_steps = save_steps,\n",
        "                                       logging_steps = logging_steps,\n",
        "                                       learning_rate = learning_rate,\n",
        "                                       weight_decay = weight_decay,\n",
        "                                       fp16 = fp16,\n",
        "                                       bf16 = bf16,\n",
        "                                       max_grad_norm = max_grad_norm,\n",
        "                                       max_steps = max_steps,\n",
        "                                       warmup_ratio = warmup_ratio,\n",
        "                                       group_by_length = group_by_length,\n",
        "                                       lr_scheduler_type = lr_scheduler_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1bKw7kWpxTY"
      },
      "outputs": [],
      "source": [
        "# Definindo os Parâmetros do Fine-Tuning Supervisionado\n",
        "dsa_trainer = SFTTrainer(model = modelo,\n",
        "                         train_dataset = dataset_carregado['train'],\n",
        "                         peft_config = peft_config,\n",
        "                         dataset_text_field = \"train\",\n",
        "                         max_seq_length = None,\n",
        "                         tokenizer = tokenizador,\n",
        "                         args = training_arguments,\n",
        "                         packing = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3fBqN7AJtTQ"
      },
      "source": [
        "> Treinamento do Modelo com o Ajuste Fino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LFznML2p6wo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e348a18a-22c5-4d32-8465-f8f6f9cacb48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 2.509, 'learning_rate': 0.000197905384816968, 'epoch': 0.09}\n",
            "{'loss': 2.2269, 'learning_rate': 0.00018733342277442523, 'epoch': 0.19}\n",
            "{'loss': 2.1996, 'learning_rate': 0.00016876519303924464, 'epoch': 0.28}\n",
            "{'loss': 2.1828, 'learning_rate': 0.00014390080687266013, 'epoch': 0.38}\n",
            "{'loss': 2.2035, 'learning_rate': 0.0001150168530248306, 'epoch': 0.47}\n",
            "{'loss': 2.2051, 'learning_rate': 8.483300876675342e-05, 'epoch': 0.56}\n",
            "{'loss': 2.1742, 'learning_rate': 5.603097596449888e-05, 'epoch': 0.66}\n",
            "{'loss': 2.1505, 'learning_rate': 3.1179692069489296e-05, 'epoch': 0.75}\n",
            "{'loss': 2.1612, 'learning_rate': 1.2629610937636283e-05, 'epoch': 0.84}\n",
            "{'loss': 2.1641, 'learning_rate': 2.0791821400001245e-06, 'epoch': 0.94}\n",
            "{'train_runtime': 1815.4954, 'train_samples_per_second': 9.395, 'train_steps_per_second': 2.349, 'train_loss': 2.2141866310540004, 'epoch': 1.0}\n",
            "CPU times: user 28min 28s, sys: 1min 53s, total: 30min 21s\n",
            "Wall time: 30min 17s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4265, training_loss=2.2141866310540004, metrics={'train_runtime': 1815.4954, 'train_samples_per_second': 9.395, 'train_steps_per_second': 2.349, 'train_loss': 2.2141866310540004, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "%%time\n",
        "dsa_trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJXpOgBFuSrc",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Salvando o modelo treinado\n",
        "dsa_trainer.model.save_pretrained(modelo_dsa)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE_4kdK7JdsC"
      },
      "source": [
        "<!-- Projeto Desenvolvido na Data Science Academy - www.datascienceacademy.com.br -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frlSLPin4IJ4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Novo texto de entrada\n",
        "prompt = \"It's rare that a movie lives up to its hype, even rarer that the hype is transcended by the actual achievement\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/docs/transformers/en/main_classes/pipelines"
      ],
      "metadata": {
        "id": "2ILPVI4NPIz-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jdt2kBWo2vJi"
      },
      "outputs": [],
      "source": [
        "# Pipeline de Análise de Sentimentos com o Modelo Ajustado\n",
        "pipe = pipeline(task = \"text-generation\",\n",
        "                model = modelo,\n",
        "                tokenizer = tokenizador,\n",
        "                max_length = 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3hDsyOA2vOg"
      },
      "outputs": [],
      "source": [
        "# Executa o pipeline e extrai o resultado\n",
        "resultado = pipe(f\"<s>[INST] {prompt} [/INST]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aZi4M_x2vUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a002ddb4-ca72-4752-caf7-b4d7a32c3c8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': \"<s>[INST] It's rare that a movie lives up to its hype, even rarer that the hype is transcended by the actual achievement [/INST] Positive [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST\"}]\n"
          ]
        }
      ],
      "source": [
        "print(resultado)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(resultado[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfeM508hr-q9",
        "outputId": "b5c45d23-5f12-4b16-c6aa-d36ef7deb0b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] It's rare that a movie lives up to its hype, even rarer that the hype is transcended by the actual achievement [/INST] Positive [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST] Negative [/INST\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkQCviG0Zta-",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63d7f780-f52f-4e04-f142-1c10da44d548"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Libera a memória\n",
        "del modelo\n",
        "del pipe\n",
        "del dsa_trainer\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Px08AD1dG8Vl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1ce18ce0a9d441f884f50d82b920d02c",
            "a062e0921160446bb57a80a71b099d75",
            "882e9ed0b7644a5eb689d2e081429fbf",
            "c9cbb7916665476f8a3eecb5d0cf0650",
            "0ccd71043b9345768edcb1972030d479",
            "de07f5a4fd5943638ab92c94775019e4",
            "ec4d220fb12b46c0a69001c0bc87ab5d",
            "7df6daeb406e4111b827be2fbcaaa30b",
            "6a17c878a1b6432487d0bab964dbf690",
            "75d1e2a953cb49a098585820c3677706",
            "12b7451893ee48238f0d832e994dfb67"
          ]
        },
        "outputId": "cb13debd-fec6-4f76-c8e4-ad6fbb2dd4f1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ce18ce0a9d441f884f50d82b920d02c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Carrega o modelo em fp16 e faz o merge com os pesos LoRA\n",
        "base_model = AutoModelForCausalLM.from_pretrained(repositorio_hf,\n",
        "                                                  low_cpu_mem_usage = True,\n",
        "                                                  return_dict = True,\n",
        "                                                  torch_dtype = torch.float16,\n",
        "                                                  device_map = \"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6zPp5ONG8Yp"
      },
      "outputs": [],
      "source": [
        "# Cria o modelo final\n",
        "modelo_dsa_final = PeftModel.from_pretrained(base_model, modelo_dsa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Se1-AzXBG_w1"
      },
      "outputs": [],
      "source": [
        "# Faz o merge e descarrega o modelo\n",
        "modelo_dsa_final = modelo_dsa_final.merge_and_unload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQn30cRtAZ-P",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Carrega o tokenizador\n",
        "tokenizador_dsa = AutoTokenizer.from_pretrained(repositorio_hf, trust_remote_code = True)\n",
        "tokenizador_dsa.pad_token = tokenizador_dsa.eos_token\n",
        "tokenizador_dsa.padding_side = \"right\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-U6l10AxmymR",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf57dc45-235a-4343-ac64-9b6d60dafffd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('novo_modelo-dsa-llm-projeto2/tokenizer_config.json',\n",
              " 'novo_modelo-dsa-llm-projeto2/special_tokens_map.json',\n",
              " 'novo_modelo-dsa-llm-projeto2/tokenizer.model',\n",
              " 'novo_modelo-dsa-llm-projeto2/added_tokens.json',\n",
              " 'novo_modelo-dsa-llm-projeto2/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# Salva modelo e tokenizador\n",
        "modelo_dsa_final.save_pretrained('novo_modelo-dsa-llm-projeto2')\n",
        "tokenizador_dsa.save_pretrained('novo_modelo-dsa-llm-projeto2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qtj5FBQFqgb"
      },
      "outputs": [],
      "source": [
        "# Novo texto de entrada\n",
        "prompt = \"It's rare that a movie lives up to its hype, even rarer that the hype is transcended by the actual achievement\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wD7Omii_Fqjd"
      },
      "outputs": [],
      "source": [
        "# Cria o pipeline\n",
        "pipe = pipeline(task = \"text-generation\",\n",
        "                model = modelo_dsa_final,\n",
        "                tokenizer = tokenizador_dsa,\n",
        "                max_length = 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwVzL7jrFqml"
      },
      "outputs": [],
      "source": [
        "# Executa o pipeline e extrai o resultado\n",
        "resultado = pipe(f\"<s>[INST] {prompt} [/INST]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YWrAyoE07Lh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80936a3c-ad5e-4bdc-a1a8-51a7e725cd57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': \"<s>[INST] It's rare that a movie lives up to its hype, even rarer that the hype is transcended by the actual achievement [/INST] Positive:\\n  * The movie is visually stunning, with a unique and captivating style.\\n  * The story is engaging and thought-provoking, with a strong emotional impact.\\n  * The acting is superb, with a standout performance from Joaquin Phoenix.\\n  * The movie is well-written and well-directed, with a strong sense of pacing and tone.\\n  * The movie is a powerful and moving experience, with a strong emotional impact.\\n  * The movie is a must-see for fans of the genre, and for anyone who appreciates a well-crafted film.\\n  * The movie is a great example of the power of cinema, and the ability of filmmakers to create\"}]\n"
          ]
        }
      ],
      "source": [
        "print(resultado)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos não apenas classificar o sentimento.\n",
        "# Vamos gerar texto positivo e/ou negativo a partir da avaliação (texto) inicial.\n",
        "print(resultado[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMbswQgMOHAP",
        "outputId": "80bb3a08-fe1d-4c95-cf77-d077ad2860df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] It's rare that a movie lives up to its hype, even rarer that the hype is transcended by the actual achievement [/INST] Positive:\n",
            "  * The movie is visually stunning, with a unique and captivating style.\n",
            "  * The story is engaging and thought-provoking, with a strong emotional impact.\n",
            "  * The acting is superb, with a standout performance from Joaquin Phoenix.\n",
            "  * The movie is well-written and well-directed, with a strong sense of pacing and tone.\n",
            "  * The movie is a powerful and moving experience, with a strong emotional impact.\n",
            "  * The movie is a must-see for fans of the genre, and for anyone who appreciates a well-crafted film.\n",
            "  * The movie is a great example of the power of cinema, and the ability of filmmakers to create\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJq2oQL8Q1C1",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Libera a memória da GPU\n",
        "from numba import cuda\n",
        "device = cuda.get_current_device()\n",
        "device.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c01jjsCwmymS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0cdf902-0b60-42f9-dd8f-c77f5cfb0b44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Data Science Academy\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%watermark -a \"Data Science Academy\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EW_3C2hS1OOt"
      },
      "outputs": [],
      "source": [
        "#%watermark -v -m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPpHlQzH1OOt"
      },
      "outputs": [],
      "source": [
        "#%watermark --iversions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lms4A2Yb1OOt"
      },
      "source": [
        "# Fim"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4a736b9f243946c4884f498413df2d65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dcb025fcf9674fe9b4acfd4a8d2806c6",
              "IPY_MODEL_409755f60a624dbda1dcf83df61ff640",
              "IPY_MODEL_536d6ff66192425ca393c55cd6052a20"
            ],
            "layout": "IPY_MODEL_3b5d13958f5d4cc4862fa940b1e50cde"
          }
        },
        "dcb025fcf9674fe9b4acfd4a8d2806c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ed73dfb1b0b4c068eea4d8af22589b7",
            "placeholder": "​",
            "style": "IPY_MODEL_0ce4e980d36740d68d0e5bf404fbde12",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "409755f60a624dbda1dcf83df61ff640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94791cbdf7a341cc9a94ac0f289aecb4",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dfa63bc79f99408292f36b090082a5de",
            "value": 2
          }
        },
        "536d6ff66192425ca393c55cd6052a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5ef973d5a294f129ecad6545980f872",
            "placeholder": "​",
            "style": "IPY_MODEL_ace4cf0d1c0e4bcfa18bf8aedec77b9f",
            "value": " 2/2 [00:04&lt;00:00,  2.21s/it]"
          }
        },
        "3b5d13958f5d4cc4862fa940b1e50cde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ed73dfb1b0b4c068eea4d8af22589b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ce4e980d36740d68d0e5bf404fbde12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94791cbdf7a341cc9a94ac0f289aecb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfa63bc79f99408292f36b090082a5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5ef973d5a294f129ecad6545980f872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ace4cf0d1c0e4bcfa18bf8aedec77b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ce18ce0a9d441f884f50d82b920d02c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a062e0921160446bb57a80a71b099d75",
              "IPY_MODEL_882e9ed0b7644a5eb689d2e081429fbf",
              "IPY_MODEL_c9cbb7916665476f8a3eecb5d0cf0650"
            ],
            "layout": "IPY_MODEL_0ccd71043b9345768edcb1972030d479"
          }
        },
        "a062e0921160446bb57a80a71b099d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de07f5a4fd5943638ab92c94775019e4",
            "placeholder": "​",
            "style": "IPY_MODEL_ec4d220fb12b46c0a69001c0bc87ab5d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "882e9ed0b7644a5eb689d2e081429fbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7df6daeb406e4111b827be2fbcaaa30b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a17c878a1b6432487d0bab964dbf690",
            "value": 2
          }
        },
        "c9cbb7916665476f8a3eecb5d0cf0650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75d1e2a953cb49a098585820c3677706",
            "placeholder": "​",
            "style": "IPY_MODEL_12b7451893ee48238f0d832e994dfb67",
            "value": " 2/2 [00:04&lt;00:00,  2.22s/it]"
          }
        },
        "0ccd71043b9345768edcb1972030d479": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de07f5a4fd5943638ab92c94775019e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec4d220fb12b46c0a69001c0bc87ab5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7df6daeb406e4111b827be2fbcaaa30b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a17c878a1b6432487d0bab964dbf690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75d1e2a953cb49a098585820c3677706": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12b7451893ee48238f0d832e994dfb67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}